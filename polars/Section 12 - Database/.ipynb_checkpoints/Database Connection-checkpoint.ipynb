{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46f17f5-db6f-4d6f-be5e-2b14efdbdc8a",
   "metadata": {},
   "source": [
    "# Reading from and writing to a database\n",
    "By the end of this lecture you will be able to:\n",
    "- Create `SQLite` database\n",
    "- read from a SQL database\n",
    "- apply row and column filters\n",
    "- Read from client server database\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61912f0-27d2-4907-b594-20c5ccbb95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d6f9da-396f-43d9-b746-2fd30732852f",
   "metadata": {},
   "source": [
    "## Creating a SQLite database\n",
    "\n",
    "For this lecture we first create a local database with SQLite. A SQLite database is simply a file on disk. \n",
    "\n",
    "We create a `DataFrame` with 10k rows of Sample_Superstore  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d13315d4-1f0a-4120-a682-40aba40cb8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file = '../../Files/Sample_Superstore-1.csv'\n",
    "\n",
    "df = pl.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f0292-1ea5-42d5-8050-70ab533662a8",
   "metadata": {},
   "source": [
    "Before we write to the database we need to create a directory to hold it.\n",
    "\n",
    "First we set the path to the directory where we create the SQLite database file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7a4b128-8418-4e3a-8ef7-7a1dbeb05231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sqliteDBDirectory = Path(\"data/sqlite/Sample_Superstore\")\n",
    "if not sqliteDBDirectory.exists():\n",
    "    #if this does not yet exist we create it\n",
    "    sqliteDBDirectory.mkdir(parents=True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2fb87-db00-4177-b329-600f35145851",
   "metadata": {},
   "source": [
    "We set the path to the SQLite database file that we will create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a12bf40c-13ef-4864-bc8f-5851513caaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sqliteDBPath = sqliteDBDirectory / \"Sample_Superstore.sqlite\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d175ac-4de1-4f05-819b-fdc18871e895",
   "metadata": {},
   "source": [
    "### Engines for writing to a database\n",
    "To work with a database we need to specify an engine to communicate between Polars and the database. The options are:\n",
    "- SQLalchemy and\n",
    "- Arrow Database Connectivity (ADBC)\n",
    "\n",
    "#### SQLalchemy\n",
    "If we choose SQLalchemy then Polars simply creates a Pandas `DataFrame` backed by PyArrow instead of Numpy (a zero-copy operation).\n",
    "\n",
    "You can do this as well if you want to have full control over operations:\n",
    "```python\n",
    "            df.to_pandas(use_pyarrow_extension_array=True).to_sql(\n",
    "                name=table_name, con=engine, if_exists=if_exists\n",
    "            )\n",
    "```\n",
    "Polars then uses the standard `to_sql` Pandas method on that `DataFrame`.\n",
    "SQLalchemy is a tried and test approach that works for many different databases.\n",
    "\n",
    "#### Arrow Database Connectivity (ADBC)\n",
    "ADBC is a promising new approach built around Apache Arrow. It *should* have advantages over SQLalchemy in terms of performance and memory usage. However, it is still early days for ADBC and the feature set is still limited compared to SQLalchemy. If ADBC doesn't work for your situation now then stick with SQLalchemy and check back in a few months.\n",
    "\n",
    "### Creating a database\n",
    "In this example we create a SQLite database with ADBC.\n",
    "\n",
    "To work with SQLite with ADBC we need to install an additional python package\n",
    "\n",
    "For more info: https://www.sqlite.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c59a70b-abfd-4140-b482-08032d4dc945",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adbc_driver_sqlite in /Users/bharatbhushan/Documents/The Fun Data Labs/work/git/workspace/myenv/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: importlib-resources>=1.3 in /Users/bharatbhushan/Documents/The Fun Data Labs/work/git/workspace/myenv/lib/python3.9/site-packages (from adbc_driver_sqlite) (6.5.2)\n",
      "Requirement already satisfied: adbc-driver-manager in /Users/bharatbhushan/Documents/The Fun Data Labs/work/git/workspace/myenv/lib/python3.9/site-packages (from adbc_driver_sqlite) (1.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/bharatbhushan/Documents/The Fun Data Labs/work/git/workspace/myenv/lib/python3.9/site-packages (from importlib-resources>=1.3->adbc_driver_sqlite) (3.21.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/bharatbhushan/Documents/The Fun Data Labs/work/git/workspace/myenv/lib/python3.9/site-packages (from adbc-driver-manager->adbc_driver_sqlite) (4.12.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Users/bharatbhushan/Documents/The Fun Data Labs/work/git/workspace/myenv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install adbc_driver_sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e08ed-95b4-45d8-affd-5cb78e061f88",
   "metadata": {},
   "source": [
    "The connection URI for a SQLite database on disk must begin with `sqlite:///` followed by the path to the database file. We call `as_posix` on the `Path` object to extract the path as a string before writing the data to the database in a table called `records`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ca35cc3-53d7-4ee3-ae3b-7232fe94987e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqlite:///data/sqlite/Sample_Superstore/Sample_Superstore.sqlite'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uri = \"sqlite:///\" + sqliteDBPath.as_posix()\n",
    "uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d6c4b-68f6-49ca-b4ff-81aeeb4c5abf",
   "metadata": {},
   "source": [
    "We now write the `DataFrame` to the `records` table in the database. We replace the table if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8597d94-b800-40d4-8792-ecb6a29f0948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uri = \"sqlite:///\" + sqliteDBPath.as_posix()\n",
    "if not sqliteDBPath.exists():\n",
    "    # if the database doesn't exist then create it\n",
    "    (\n",
    "        df\n",
    "        .sort(\"Customer_ID\")\n",
    "        .write_database(\n",
    "            table_name = \"records\",\n",
    "            connection = uri,\n",
    "            if_table_exists = \"replace\",\n",
    "            engine=\"adbc\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73973cf-0840-4d11-9e6f-e15689b1d068",
   "metadata": {},
   "source": [
    "## Reading from a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac24e5-7e4c-4034-bdc3-178ae7f7ee17",
   "metadata": {},
   "source": [
    "We query the database with the `uri` connection string above and a sql query.\n",
    "\n",
    "In this example we select 3 rows from the records table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5218dba1-297e-44ac-a02d-726bf9c4f640",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Row_ID</th><th>Order_ID</th><th>Order_Date</th><th>Ship_Date</th><th>Ship_Mode</th><th>Customer_ID</th><th>Customer_Name</th><th>Segment</th><th>Country</th><th>City</th><th>State</th><th>Postal_Code</th><th>Region</th><th>Product_ID</th><th>Category</th><th>Sub_Category</th><th>Product_Name</th><th>Sales</th><th>Quantity</th><th>Discount</th><th>Profit</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1160</td><td>&quot;CA-2017-147039&quot;</td><td>&quot;29-06-2017&quot;</td><td>&quot;04-07-2017&quot;</td><td>&quot;Standard Class&quot;</td><td>&quot;AA-10315&quot;</td><td>&quot;Alex Avila&quot;</td><td>&quot;Consumer&quot;</td><td>&quot;United States&quot;</td><td>&quot;Minneapolis&quot;</td><td>&quot;Minnesota&quot;</td><td>55407</td><td>&quot;Central&quot;</td><td>&quot;OFF-AP-10000576&quot;</td><td>&quot;Office Supplies&quot;</td><td>&quot;Appliances&quot;</td><td>&quot;Belkin 325VA UPS Surge Protect…</td><td>362.94</td><td>3</td><td>0.0</td><td>90.735</td></tr><tr><td>1161</td><td>&quot;CA-2017-147039&quot;</td><td>&quot;29-06-2017&quot;</td><td>&quot;04-07-2017&quot;</td><td>&quot;Standard Class&quot;</td><td>&quot;AA-10315&quot;</td><td>&quot;Alex Avila&quot;</td><td>&quot;Consumer&quot;</td><td>&quot;United States&quot;</td><td>&quot;Minneapolis&quot;</td><td>&quot;Minnesota&quot;</td><td>55407</td><td>&quot;Central&quot;</td><td>&quot;OFF-BI-10004654&quot;</td><td>&quot;Office Supplies&quot;</td><td>&quot;Binders&quot;</td><td>&quot;Avery Binding System Hidden Ta…</td><td>11.54</td><td>2</td><td>0.0</td><td>5.77</td></tr><tr><td>1300</td><td>&quot;CA-2015-121391&quot;</td><td>&quot;04-10-2015&quot;</td><td>&quot;07-10-2015&quot;</td><td>&quot;First Class&quot;</td><td>&quot;AA-10315&quot;</td><td>&quot;Alex Avila&quot;</td><td>&quot;Consumer&quot;</td><td>&quot;United States&quot;</td><td>&quot;San Francisco&quot;</td><td>&quot;California&quot;</td><td>94109</td><td>&quot;West&quot;</td><td>&quot;OFF-ST-10001590&quot;</td><td>&quot;Office Supplies&quot;</td><td>&quot;Storage&quot;</td><td>&quot;Tenex Personal Project File wi…</td><td>26.96</td><td>2</td><td>0.0</td><td>7.0096</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 21)\n",
       "┌────────┬────────────────┬────────────┬────────────┬───┬────────┬──────────┬──────────┬────────┐\n",
       "│ Row_ID ┆ Order_ID       ┆ Order_Date ┆ Ship_Date  ┆ … ┆ Sales  ┆ Quantity ┆ Discount ┆ Profit │\n",
       "│ ---    ┆ ---            ┆ ---        ┆ ---        ┆   ┆ ---    ┆ ---      ┆ ---      ┆ ---    │\n",
       "│ i64    ┆ str            ┆ str        ┆ str        ┆   ┆ f64    ┆ i64      ┆ f64      ┆ f64    │\n",
       "╞════════╪════════════════╪════════════╪════════════╪═══╪════════╪══════════╪══════════╪════════╡\n",
       "│ 1160   ┆ CA-2017-147039 ┆ 29-06-2017 ┆ 04-07-2017 ┆ … ┆ 362.94 ┆ 3        ┆ 0.0      ┆ 90.735 │\n",
       "│ 1161   ┆ CA-2017-147039 ┆ 29-06-2017 ┆ 04-07-2017 ┆ … ┆ 11.54  ┆ 2        ┆ 0.0      ┆ 5.77   │\n",
       "│ 1300   ┆ CA-2015-121391 ┆ 04-10-2015 ┆ 07-10-2015 ┆ … ┆ 26.96  ┆ 2        ┆ 0.0      ┆ 7.0096 │\n",
       "└────────┴────────────────┴────────────┴────────────┴───┴────────┴──────────┴──────────┴────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_database_uri(\"select * from records limit 3\", uri=uri, engine=\"adbc\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a58d9-4efa-4e51-a574-993d2c577cd5",
   "metadata": {},
   "source": [
    "## Reading from a client-server database\n",
    "To read from a client-server database like Postgres, MySQL, Oracle, etc then the connection string requires the standard connection and login details such as\n",
    "```python\n",
    "uri = \"postgresql://username:password@server:port/database\"\n",
    "pl.read_database_uri(sql=\"select * from records\",uri=uri)\n",
    "```\n",
    "\n",
    "We are using this database which is working online and dont need to install locally, We just need to connect with it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24398fd3-698c-48dc-9655-2b76b545027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"postgresql://postgres:123456@localhost:5432/polars_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c9d9d0-7cb8-4f77-8809-d6bd07e4ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: connectorx in /Users/bharatbhushan/Documents/The Fun Data Labs/work/git/workspace/myenv/lib/python3.9/site-packages (0.3.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Users/bharatbhushan/Documents/The Fun Data Labs/work/git/workspace/myenv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install connectorx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d248c51d-1dfa-4c33-a66a-78b8797d5de1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "required package 'connectorx' not found.\nPlease install using the command `pip install connectorx`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect * from employees \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_database_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df\n",
      "File \u001b[0;32m~/Documents/The Fun Data Labs/work/git/workspace/myenv/lib/python3.9/site-packages/polars/io/database/functions.py:433\u001b[0m, in \u001b[0;36mread_database_uri\u001b[0;34m(query, uri, partition_on, partition_range, partition_num, protocol, engine, schema_overrides, execute_options)\u001b[0m\n\u001b[1;32m    431\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnectorx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m engine does not support use of `execute_options`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_sql_connectorx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madbc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(query, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/The Fun Data Labs/work/git/workspace/myenv/lib/python3.9/site-packages/polars/io/database/_utils.py:41\u001b[0m, in \u001b[0;36m_read_sql_connectorx\u001b[0;34m(query, connection_uri, partition_on, partition_range, partition_num, protocol, schema_overrides)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_sql_connectorx\u001b[39m(\n\u001b[1;32m     33\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m     34\u001b[0m     connection_uri: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     schema_overrides: SchemaDict \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m---> 41\u001b[0m     cx \u001b[38;5;241m=\u001b[39m \u001b[43mimport_optional\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconnectorx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         tbl \u001b[38;5;241m=\u001b[39m cx\u001b[38;5;241m.\u001b[39mread_sql(\n\u001b[1;32m     44\u001b[0m             conn\u001b[38;5;241m=\u001b[39mconnection_uri,\n\u001b[1;32m     45\u001b[0m             query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m             protocol\u001b[38;5;241m=\u001b[39mprotocol,\n\u001b[1;32m     51\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/The Fun Data Labs/work/git/workspace/myenv/lib/python3.9/site-packages/polars/dependencies.py:270\u001b[0m, in \u001b[0;36mimport_optional\u001b[0;34m(module_name, err_prefix, err_suffix, min_version, min_err_prefix, install_message)\u001b[0m\n\u001b[1;32m    265\u001b[0m     suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_suffix\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err_suffix \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m     err_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m    267\u001b[0m         install_message\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install using the command `pip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m     )\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(err_message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_version:\n\u001b[1;32m    273\u001b[0m     min_version \u001b[38;5;241m=\u001b[39m parse_version(min_version)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: required package 'connectorx' not found.\nPlease install using the command `pip install connectorx`."
     ]
    }
   ],
   "source": [
    "query = \"select * from employees \"\n",
    "df = pl.read_database_uri(query, uri)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d80149-eb68-4df9-838c-d4b924ac246b",
   "metadata": {},
   "source": [
    "## Filtering rows and selecting columns\n",
    "The `pl.read_database_uri` function works only in eager mode. If you read a database and then `select` a column or `filter` rows then the entire database is read into memory before the `select` or `filter` is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a231b2-e6e0-4dc8-ae93-d3304807b5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7111f8a2-ec93-44e7-9c00-da2ed147f740",
   "metadata": {},
   "source": [
    "To apply the filters in the database you need to specify the filters in the SQL string using `where`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581faef-5fc4-4f86-8aed-84d53883a752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b676bd4-b56c-4c3e-bc26-68b1094be5e4",
   "metadata": {},
   "source": [
    "While to select columns you specify the columns in the SQL string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca18e29-e40a-4104-b69e-258dd7e40621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885104d-e41b-4b32-a265-7fcce733e49b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078febe-53c2-41d9-9214-dfc9191e91c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f9339-699a-4fdd-9bd3-4d56f6a95b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aafd3a-bf54-4dac-914e-c3dfab1ffbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fbb9dd-3dec-4300-91f6-66f461de15af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
